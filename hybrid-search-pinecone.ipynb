{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9186801,"sourceType":"datasetVersion","datasetId":5553318}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color = 'lightblue'> Installing Necessary Packages","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade --quiet pinecone pinecone-client pinecone-notebooks\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:48:03.335761Z","iopub.execute_input":"2024-08-16T14:48:03.336168Z","iopub.status.idle":"2024-08-16T14:48:20.875733Z","shell.execute_reply.started":"2024-08-16T14:48:03.336137Z","shell.execute_reply":"2024-08-16T14:48:20.874068Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install pinecone-text","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:35:15.188536Z","iopub.execute_input":"2024-08-16T15:35:15.188953Z","iopub.status.idle":"2024-08-16T15:35:36.583504Z","shell.execute_reply.started":"2024-08-16T15:35:15.188921Z","shell.execute_reply":"2024-08-16T15:35:36.582174Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Collecting pinecone-text\n  Downloading pinecone_text-0.9.0-py3-none-any.whl.metadata (10 kB)\nCollecting mmh3<5.0.0,>=4.1.0 (from pinecone-text)\n  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting nltk<4.0.0,>=3.6.5 (from pinecone-text)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: numpy<2.0,>=1.21.5 in /opt/conda/lib/python3.10/site-packages (from pinecone-text) (1.26.4)\nCollecting python-dotenv<2.0.0,>=1.0.1 (from pinecone-text)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: requests<3.0.0,>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-text) (2.32.3)\nCollecting types-requests<3.0.0,>=2.25.0 (from pinecone-text)\n  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\nCollecting wget<4.0,>=3.2 (from pinecone-text)\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text) (4.66.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->pinecone-text) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->pinecone-text) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->pinecone-text) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->pinecone-text) (2024.7.4)\nCollecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.25.0->pinecone-text)\n  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\nDownloading pinecone_text-0.9.0-py3-none-any.whl (23 kB)\nDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nDownloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\nDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=67f1dc1e99ebc6b78fe97bd3e40315eeb6679266a2222fbcec1512366156cffe\n  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\nSuccessfully built wget\nInstalling collected packages: wget, mmh3, urllib3, python-dotenv, nltk, types-requests, pinecone-text\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: python-dotenv\n    Found existing installation: python-dotenv 1.0.0\n    Uninstalling python-dotenv-1.0.0:\n      Successfully uninstalled python-dotenv-1.0.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.2 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mmh3-4.1.0 nltk-3.8.1 pinecone-text-0.9.0 python-dotenv-1.0.1 types-requests-2.32.0.20240712 urllib3-2.1.0 wget-3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install langchain langchain_community\nfrom langchain_community.retrievers import PineconeHybridSearchRetriever\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:55:20.814443Z","iopub.execute_input":"2024-08-16T14:55:20.814909Z","iopub.status.idle":"2024-08-16T14:55:43.540805Z","shell.execute_reply.started":"2024-08-16T14:55:20.814873Z","shell.execute_reply":"2024-08-16T14:55:43.539567Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Using cached langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain_community\n  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n  Downloading langchain_core-0.2.32-py3-none-any.whl.metadata (6.2 kB)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.32->langchain)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.9.0)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m819.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (2.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nDownloading langchain-0.2.14-py3-none-any.whl (997 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.32-py3-none-any.whl (389 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.99-py3-none-any.whl (140 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.14 langchain-core-0.2.32 langchain-text-splitters-0.2.2 langchain_community-0.2.12 langsmith-0.1.99 orjson-3.10.7 packaging-24.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pinecone\nfrom pinecone import Pinecone, ServerlessSpec","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:07:57.466270Z","iopub.execute_input":"2024-08-16T15:07:57.466720Z","iopub.status.idle":"2024-08-16T15:08:11.976355Z","shell.execute_reply.started":"2024-08-16T15:07:57.466687Z","shell.execute_reply":"2024-08-16T15:08:11.975220Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pinecone in /opt/conda/lib/python3.10/site-packages (5.0.1)\nRequirement already satisfied: pinecone-client==5.0.1 in /opt/conda/lib/python3.10/site-packages (from pinecone) (5.0.1)\nRequirement already satisfied: certifi>=2019.11.17 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==5.0.1->pinecone) (2024.7.4)\nRequirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==5.0.1->pinecone) (1.0.3)\nRequirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==5.0.1->pinecone) (0.0.7)\nRequirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==5.0.1->pinecone) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==5.0.1->pinecone) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client==5.0.1->pinecone) (1.26.18)\n","output_type":"stream"}]},{"cell_type":"code","source":"api_key = \"PINECONE_API_KEY\"","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:59:19.919659Z","iopub.execute_input":"2024-08-16T14:59:19.920089Z","iopub.status.idle":"2024-08-16T14:59:19.924884Z","shell.execute_reply.started":"2024-08-16T14:59:19.920058Z","shell.execute_reply":"2024-08-16T14:59:19.923838Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"index_name = 'hybrid-search-langchain-pinecone'\npc = Pinecone(api_key=api_key)\nif index_name not in pc.list_indexes().names():\n    pc.create_index(\n        name = index_name,\n        dimension = 384, #dimension of dense vector\n        metric = 'dotproduct', # sparse values for syntactic (keyword) search\n        spec = ServerlessSpec(cloud = 'aws', region = 'us-east-1'),\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:10:57.763923Z","iopub.execute_input":"2024-08-16T15:10:57.764294Z","iopub.status.idle":"2024-08-16T15:11:03.155889Z","shell.execute_reply.started":"2024-08-16T15:10:57.764265Z","shell.execute_reply":"2024-08-16T15:11:03.154523Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"index = pc.Index(index_name)\nindex","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:12:04.301036Z","iopub.execute_input":"2024-08-16T15:12:04.301432Z","iopub.status.idle":"2024-08-16T15:12:04.369700Z","shell.execute_reply.started":"2024-08-16T15:12:04.301401Z","shell.execute_reply":"2024-08-16T15:12:04.368651Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<pinecone.data.index.Index at 0x7ff2a41cf280>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install python-dotenv\n!pip install langchain_huggingface\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_huggingface import HuggingFaceEmbeddings\nload_dotenv()\nembeddings = HuggingFaceEmbeddings(model_name = 'all-MiniLM-L6-v2')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:18:32.510855Z","iopub.execute_input":"2024-08-16T15:18:32.511270Z","iopub.status.idle":"2024-08-16T15:19:27.380736Z","shell.execute_reply.started":"2024-08-16T15:18:32.511242Z","shell.execute_reply":"2024-08-16T15:19:27.379545Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.0)\nCollecting langchain_huggingface\n  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.23.4)\nRequirement already satisfied: langchain-core<0.3,>=0.1.52 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.2.32)\nCollecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.19.1)\nRequirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.99)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.5.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.2.3)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (9.5.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.7)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\nDownloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m808.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers, langchain_huggingface\nSuccessfully installed langchain_huggingface-0.0.3 sentence-transformers-3.0.1\n","output_type":"stream"},{"name":"stderr","text":"2024-08-16 15:19:10.828287: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-16 15:19:10.828420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-16 15:19:10.969115: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfeb0d2f7b064e38b3a4678fa1960ac7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4920d89003b40b5853a135f6063ea3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f91a713fe41f483893fe8caae43adcbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"828a4e27ed7a482ca60186eb9b4a5630"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5cb8ec1114e429bae11d3666e9a08a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72c9ed20191342e2b91e05e79424a7a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c427541c51d4b8980fd05d84d132f38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1122fc596a044b0893309c49b8547fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a576cde3ee3f42b9be9f4df6232d1bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35671ca7fe1e403bb1277df612a7553c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4e705e05334f6bbf81d4a036d3cf46"}},"metadata":{}}]},{"cell_type":"code","source":"load_dotenv(\"/kaggle/input/api-keys/.env\")\nhf_api_key = os.getenv('HUGGINGFACE_API_KEY')\nos.environ['HUGGINGFACE_API_KEY'] = hf_api_key\nos.environ['HUGGINGFACE_API_KEY'] = os.getenv('HUGGINGFACE_API_KEY')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:30:42.102420Z","iopub.execute_input":"2024-08-16T15:30:42.102847Z","iopub.status.idle":"2024-08-16T15:30:42.111862Z","shell.execute_reply.started":"2024-08-16T15:30:42.102815Z","shell.execute_reply":"2024-08-16T15:30:42.110688Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"embeddings","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:31:16.658024Z","iopub.execute_input":"2024-08-16T15:31:16.658987Z","iopub.status.idle":"2024-08-16T15:31:16.665716Z","shell.execute_reply.started":"2024-08-16T15:31:16.658953Z","shell.execute_reply":"2024-08-16T15:31:16.664414Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"HuggingFaceEmbeddings(client=SentenceTransformer(\n  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n  (2): Normalize()\n), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"},"metadata":{}}]},{"cell_type":"code","source":"from pinecone_text.sparse import BM25Encoder\nbm25_encoder = BM25Encoder().default()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T15:35:50.029422Z","iopub.execute_input":"2024-08-16T15:35:50.030538Z","iopub.status.idle":"2024-08-16T15:35:54.447030Z","shell.execute_reply.started":"2024-08-16T15:35:50.030488Z","shell.execute_reply":"2024-08-16T15:35:54.446033Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"retriever.add_texts(\n['Prompts are how humans communicate with LLMs. Informative prompts are essential for guiding LLMs to produce the desired output. However, prompt engineering is often tedious and time-consuming, requiring significant expertise, limiting its widespread use. We propose Conversational Prompt Engineering (CPE), a user-friendly tool that helps users create personalized prompts for their specific tasks. CPE uses a chat model to briefly interact with users, helping them articulate their output preferences and integrating these into the promp',\n    'The process includes two main stages: first, the model uses user-provided unlabeled data to generate data-driven questions and utilize user responses to shape the initial instruction.',\n    'Then, the model shares the outputs generated by the instruction and uses user feedback to further refine the instruction and the outputs.',\n    'The final result is a few-shot prompt, where the outputs approved by the user serve as few-shot examples. A user study on summarization tasks demonstrates the value of CPE in creating personalized, high-performing prompts.',\n    'The results suggest that the zero-shot prompt obtained is comparable to its – much longer – few-shot counterpart, indicating significant savings in scenarios involving repetitive tasks with large.',\n]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:17:38.855689Z","iopub.execute_input":"2024-08-16T16:17:38.856112Z","iopub.status.idle":"2024-08-16T16:17:39.506857Z","shell.execute_reply.started":"2024-08-16T16:17:38.856079Z","shell.execute_reply":"2024-08-16T16:17:39.505549Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73765c6ff07f4a229f9ec25b6589eceb"}},"metadata":{}}]},{"cell_type":"code","source":"# Original abstract paper data\nabstract_paper = [\n    ['Prompts are how humans communicate with LLMs. Informative prompts are essential for guiding LLMs to produce the desired output. However, prompt engineering is often tedious and time-consuming, requiring significant expertise, limiting its widespread use. We propose Conversational Prompt Engineering (CPE), a user-friendly tool that helps users create personalized prompts for their specific tasks. CPE uses a chat model to briefly interact with users, helping them articulate their output preferences and integrating these into the promp'],\n    ['The process includes two main stages: first, the model uses user-provided unlabeled data to generate data-driven questions and utilize user responses to shape the initial instruction.'],\n    ['Then, the model shares the outputs generated by the instruction and uses user feedback to further refine the instruction and the outputs.'],\n    ['The final result is a few-shot prompt, where the outputs approved by the user serve as few-shot examples. A user study on summarization tasks demonstrates the value of CPE in creating personalized, high-performing prompts.'],\n    ['The results suggest that the zero-shot prompt obtained is comparable to its – much longer – few-shot counterpart, indicating significant savings in scenarios involving repetitive tasks with large.'],\n]\n\n# Flatten the list of lists into a single list of strings\nflattened_abstract_paper = [' '.join(paragraph) for paragraph in abstract_paper]\n\n# Initialize the BM25 encoder\nbm25_encoder = BM25Encoder().default()\n\n# Fit the encoder with the flattened list of strings\nbm25_encoder.fit(flattened_abstract_paper)\n\n# Store the values in a JSON file\nbm25_encoder.dump('bm25_encoder.json')\n\n# Load the encoder from the JSON file\nbm25_encoder = BM25Encoder().load(path='bm25_encoder.json')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:14:46.225496Z","iopub.execute_input":"2024-08-16T16:14:46.225920Z","iopub.status.idle":"2024-08-16T16:14:50.479237Z","shell.execute_reply.started":"2024-08-16T16:14:46.225888Z","shell.execute_reply":"2024-08-16T16:14:50.477963Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd39965cf2649f296ab7d7f9afb987e"}},"metadata":{}}]},{"cell_type":"code","source":"retriever = PineconeHybridSearchRetriever(embeddings=embeddings, sparse_encoder=bm25_encoder, index=index)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:14:50.481264Z","iopub.execute_input":"2024-08-16T16:14:50.481646Z","iopub.status.idle":"2024-08-16T16:14:50.487206Z","shell.execute_reply.started":"2024-08-16T16:14:50.481615Z","shell.execute_reply":"2024-08-16T16:14:50.485998Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"(retriever.invoke(\"Could you tell me about conversational prompt engineering\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:20:51.524357Z","iopub.execute_input":"2024-08-16T16:20:51.524790Z","iopub.status.idle":"2024-08-16T16:20:51.591897Z","shell.execute_reply.started":"2024-08-16T16:20:51.524747Z","shell.execute_reply":"2024-08-16T16:20:51.590861Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='Prompts are how humans communicate with LLMs. Informative prompts are essential for guiding LLMs to produce the desired output. However, prompt engineering is often tedious and time-consuming, requiring significant expertise, limiting its widespread use. We propose Conversational Prompt Engineering (CPE), a user-friendly tool that helps users create personalized prompts for their specific tasks. CPE uses a chat model to briefly interact with users, helping them articulate their output preferences and integrating these into the promp'),\n Document(page_content='The final result is a few-shot prompt, where the outputs approved by the user serve as few-shot examples. A user study on summarization tasks demonstrates the value of CPE in creating personalized, high-performing prompts.'),\n Document(page_content='The process includes two main stages: first, the model uses user-provided unlabeled data to generate data-driven questions and utilize user responses to shape the initial instruction.'),\n Document(page_content='The results suggest that the zero-shot prompt obtained is comparable to its – much longer – few-shot counterpart, indicating significant savings in scenarios involving repetitive tasks with large.')]"},"metadata":{}}]},{"cell_type":"code","source":"len(retriever.invoke(\"Could you tell me about conversational prompt engineering\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:21:22.706918Z","iopub.execute_input":"2024-08-16T16:21:22.707345Z","iopub.status.idle":"2024-08-16T16:21:22.778001Z","shell.execute_reply.started":"2024-08-16T16:21:22.707313Z","shell.execute_reply":"2024-08-16T16:21:22.776807Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]}]}